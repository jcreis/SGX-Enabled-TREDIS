%!TEX root = ../template.tex
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% chapter4.tex
%% NOVA thesis document file
%%
%% Chapter with lots of dummy text
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Implementation}
\label{cha:implementation}

In this chapter we describe the implementation of our prototype TREDIS, or Trusted REDIS, implemented on top of a \gls{tee} instanciated through Intel-\gls{sgx}. 
We present how we implemented the system components that make up our system model defined in \ref{cha:systemModel_and_design}.
Our implementation is deployed in an online repository in Github \footnote{https://github.com/jcreis/thesis\_implementation}.

We start by presenting the environments in which we implemented our solution in Section \ref{sec:implementationArchitecture}, along with some general technologies we used to implement our system components. Then in Section \ref{sec:implementationComponents} we describe in more detail the implementation of the components that make up the system, explaining the implementation process along with the technology stack we used to implement each one of them. Lastly, we finish with a summary in \ref{sec:implementationSummary}.


\section{Implementation Architecture}
\label{sec:implementationArchitecture}

Our prototype complies to the system model described in the previous chapter in \ref{sec:systemModel_overview} and, as we mentioned there, can be divided into two distinct parts, the client side and the server side.
The first one consists on benchmark applications, that measure simple requests to the server side of the system. We run the client on a local machine running Ubuntu 18.04.3 LTS \gls{os} on top of commodity hardware:
\vspace{5mm}
\begin{lstlisting}
CPU:Intel(R) Core(TM) i7-8550U CPU @ 1.80GHz - 4-core
RAM: 16Gb DDR4 2400MHz
Storage: Intel SSDPEKKF512G8L - 512Gb SSD M.2 NVMe
Network: Ethernet Connection (4) I219-V 1Gb/s
\end{lstlisting} 
\vspace{3mm}

As for the server part, which runs the TREDIS solution itself, we implemented it in an environment hosted on OVH \footnote{https://www.ovhcloud.com/} Cloud, on a machine running Ubuntu 18.04.4 LTS 64 bits with the following hardware specifications: 
\vspace{5mm}
\begin{lstlisting}
CPU: Intel(R) Xeon(R) E-2288G CPU @ 3.70GHz - 8-core
RAM: 4x32Gb DDR4 2666MHz 
Storage: Cannon Lake PCH SATA AHCI Controller - 4Tb HDD
Network: Ethernet Controller 10G X550T 10Gb/s
\end{lstlisting}
\vspace{3mm}

Note that Intel(R) Xeon(R) E-2288G is \gls{sgx}-enabled, which allows us to run our TREDIS solution on top of a \gls{tee} as we intended, with 128Mb size enclaves. 

In order to increase the privacy levels of our system, we opted to run each component of our TREDIS solution inside containers, as a way to increase isolation, while keeping the system modular and scalable. 
For that, we use Docker's version 19.03.6, which also allows us to integrate SCONE technology as a way to mitigate \gls{sgx} performance issues. 

Thus, we run SCONE\footnote{https://hub.docker.com/u/sconecuratedimages} images  inside each component container, allowing the application there deployed to execute inside \gls{sgx} enclaves with more efficiency. 
To note that the SCONE curated images we used run with Alpine\footnote{http://alpinelinux.org} Linux version 3.8.5 with kernel 4.15.0-101-generic.

Communications between server components are secured via TLS 1.2. Since we do not have a signing service, we generated our own Certificate Authority which we used to sign the certificates for all the components. 



\section{Implementation Components And Options}
\label{sec:implementationComponents}

In this Section, we go deeper into implementation details of our solution, specifying the technologies we used to implement each piece of it.


\subsection{TREDIS solution}

TREDIS, as we detailed in \ref{ssec:sgx_redisSolution}, is running in the OVH cloud environment and can be broken into four major components, that together make up the solution we intend to evaluate:

\textbf{Proxy}. Our Proxy component consists of an API implemented in Java 1.8.0\_201\footnote{https://docs.oracle.com/javase/8/docs/} with the help of Spring Boot v2.3.1\footnote{https://newreleases.io/project/github/spring-projects/spring-boot/release/v2.3.1.RELEASE}. It works as an entry point to our entire solution, facilitating client access to the system while also enabling it to scale. 

We implemented the proxy to accept requests over a defined endpoint in order to manipulate data inside in-memory Redis instances, through Jedis v3.3.0, which is an open-source Redis Java client provided by Redis itself. Jedis\footnote{https://github.com/redis/jedis} enables our API to perform operations over the Redis \gls{kvs} in any configuration it is set to run, whether it is running in Standalone mode or one of the more complex ones, Master-Slave or Cluster. It also allows us to set TLS connectivity to the \gls{kvs} instances with two-way authentication, where each of the endpoints (Proxy and Redis instance) trusts each other's certificates, thus securing communications between the Proxy and the Key-Value Store components.

Our proxy also holds the Authentication server certificate. It establishes a TLS link with the Authentication server in order to validate access tokens upon Client requests.

\vspace{3mm}
\textbf{Authentication Server}. For our Authentication Server, we used an open-source identity and access management server called Keycloak\footnote{https://www.keycloak.org} v11.0.2. Keycloak grants access tokens to clients that are configurated inside its own in-memory database. It works well with Spring boot framework which we used to implement the Proxy, since it can be easily configured in order to check the validity of tokens received by the Spring API.

To note that this is the only component that is part of the system and doesn't run on \gls{sgx} enclaves. Instead, it runs in a Docker container with a non-SCONE image, developed by RedHat that can be found in jboss dockerhub page\footnote{https://hub.docker.com/r/jboss/keycloak/}.

\vspace{3mm}
\textbf{Attestation Mechanism}. In order to attest our system components that run on top of \gls{sgx}, and also to reassure that they indeed run inside enclaves, we followed the SCONE's attestation mechanism consisting on a remote attestation policy that we described in the previous chapter. 

In SCONE's approach, it is a remote entity called CAS that manages all the defined secrets for the applications in the system. This entity is provided by SCONE itself, and since the service that provides images of CAS requires a subscription, we implemented the attestation mechanism using their public CAS instance, \textit{scone-cas.cf}\footnote{https://sconedocs.github.io/public-CAS/}.
We posted to the remote CAS instance the sessions where enclave's hash values are specified, along with the secrets for each application. This last ones can only be obtained if the hash value of the enclave that is trying to get them matches with the one specified before in the secret. 

Although, for CAS to do that verification, the enclave needs a quote from a quoting enclave - LAS. LAS is running in our application inside a SCONE container, and is the component that contains the attestation key used to create a Quote, which is a message signed by LAS with that specific key that CAS will be able to verify, since CAS also knows the attestation key. With this quote, CAS will know that a LAS instance locally attested the enclave, and can then proceed to check if the enclave is entitled to the secrets or not.

After having LAS running locally in a container in our system and by using the public CAS instance SCONE provides, we were able to add this attestation mechanism to the rest of our system components quite easily. After having the secrets defined and posted in CAS, we only needed to include a list of environment variables upon creation of the applications that we intend to attest in our system, where we specified both the CAS and LAS addresses as a way to perform this attestation upon each component start. A better demonstration on how to do this configuration is present in \cite{sconeAttestationConfig}. 

All the communications are secured through TLS, either between CAS and the containers running applications, or between those containers and LAS instance. 


\vspace{3mm}
\textbf{Key-Value Store}. As we already mentioned before, we implemented our Key-Value Store component by using Redis \gls{kvs}. To run Redis with \gls{sgx} security properties, we had to run a Redis image incorporated with SCONE, to run in a secured container. 

However, Redis images are mounted according to a configuration file, which is set upon their build. 
And since one of our objectives is to enable the \gls{kvs} component to run in various configurations in order to evaluate its behavior on top of \gls{sgx}, we build Redis images with customized configuration files for the Redis instances to run in Standalone, Master-Slave and Cluster modes. All the Redis images we build use Redis version 6.0-rc1 and have SCONE's\footnote{sconecuratedimages/apps:redis-6-alpine} as base image. 

Adding to that, building our own Redis image allowed us to specify the keys and certificates we intend to use in every instance, needed for establishing secured TLS connections with other components over the network. To note that in Redis configurations set to run with multiple Redis instances, like Master-Slave or Cluster, we use the same keys and certificates in every instance in order to facilitate the implementation of such configurations. We consider this to be unpratical and unsafe in a real world application, however we opted to do so in order to prevent an extra layer of complexity for the implementation phase of our solution.


\vspace{3mm}
Each component that runs inside a container with a SCONE-based image in our TREDIS solution, and so on top of \gls{sgx} enclaves, is deployed as Figure \ref{fig:instanceStack} shows:
\begin{figure}[htbp]
	\centering
	{\includegraphics[width=0.7\linewidth]{instance_stack}}
	\caption{Server Component Technology Stack}
	\label{fig:instanceStack}
\end{figure}

A container runs a Scone-based application image on top of an enclave. Inside the enclave, besides the application code, it is present a small static library provided by SCONE which allows the application to make some system calls (the ones that are included in this small library) to the \gls{os} running in the host machine. OpenSSL, which provides TLS and SSL protocols, is one of the static libraries included by SCONE, but represented in the figure above as independent from the static library component due to importance. By having OpenSSL statically inside the enclave, components can communicate with each other securely over the network without inducing in any tangible overhead. 



\subsection{Client-based benchmarks}

To implement the Client, first we tested our solution directly against the \gls{kvs} instances themselves, in order to get base values for the metrics we intend to study. For that we used redis-benchmark, which comes directly with the installation of Redis itself, therefore its version is induced by the Redis version present on the machine.

However, since our solution was designed with a customized entry point API (our Proxy component) which redirects client requests to the Redis \gls{kvs} instances, we were unable to find a way of setting redis-benchmark to make requests to the Proxy. 
Thus, in order to perform a experimental evaluation over the entire TREDIS solution, we opted to used Jmeter\footnote{https://jmeter.apache.org/} version 5.3 as a way to reach our Proxy endpoint, thus benchmarking the behavior of our solution without needing to exclude any component. Also, by being designed by a different organization than the provider of the \gls{kvs} we are studying, it gives an extra level of guarantee in our results, just in case.

With the clients defined as above, we were able to evaluate our system as we intended. 
We made simple \gls{crud} operations to the in-memory Redis \gls{kvs} instances running inside the TREDIS solution, either through the Proxy or directly to Redis instances, along with some other specific tests that we will detail later in this thesis, in order to analyze performance levels, scalability capabilities, resource usage, and other metrics we found a necessity to evaluate.



\section{Summary}
\label{sec:implementationSummary}


resumo do modelo de sistema que implementamos, as tecnologias em resumo e essas cenas

TODO - falar daquilo de como sabemos se as cenas estão mesmo a correr na enclave (e apontar po site do scone onde mostram o programa que ve isso)

From SCONE: 
HOW CAN I ENFORCE/VERIFY THAT A SERVICE/PROGRAM RUNS INSIDE OF AN ENCLAVE?
You need to attest that your program runs inside of an enclave. SCONE supports transparent attestation with the help of CAS.

On the application level, one often does not want to perform an explicit attestation but an implicit attestation with the help of TLS to reduce/eliminate the amount of reengineering that is needed. The idea is that a service can only provide the correct TLS certificate if it runs inside an enclave. To do so, one would give the enclave an encrypted TLS private key in the file system (can be generate by Scone CAS if this is requested) and the enclave gets only access to the encryption key after a successful attestation. The decryption of the TLS private key is done transparently by SCONE.


% \lipsum[1-100]
% \lipsum[1-700]
% \lipsum[1-700]
% \lipsum[1-700]
% \lipsum[1-700]
% \lipsum[1-700]
% \lipsum[1-700]
% \lipsum[1-700]
% \lipsum[1-700]
