%!TEX root = ../template.tex
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% chapter3.tex
%% NOVA thesis document file
%%
%% Chapter with a short laext tutorial and examples
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{System model and design options}
\label{cha:systemModel_and_designOptions}

In this chapter we present the architecture overview of the system model for our solution. We introduce an architecture model that is able to assure confidentiallity and integrity, according to our adversary model, to the execution of unmodified applications that run sensitive data on cloud computing servers, by leveraging trusted computing tecniques provided by both software and hardware, inside \gls{tee}s. All this without crippling too much the performance levels of the overall system.

The system model defined in the next chapter is later described in the thesis with greater detail, as an implementation prototype capable of applying this theoretical concepts described before.

In Section \cite{sec:systemModel_overview} we describe a general overview of the system as a whole, 

TODO


-----
In Section
4.1 and Section 4.2 we describe the bigger picture and what are the assumptions that
we based ourselves on the creation the system. After, we will look into more detail on
the components and operations that our system works with in Sections 4.3, 4.4 and 4.5.
We will also look onto the Protocols and Processes necessary to start and maintain our
solution in Sections 4.6 and 4.7. At last, we finish with a Summary in Section 4.8.



\section{System model overview} % (fold)
\label{sec:systemModel_overview}

Our solution can be seen in figure (?), which is a macro overview of the system. As we can see in the figure, the solution we focused on implementing can be divided in two sides, client side and server side, where clients interact with an in-memory \gls{kvs} running inside a cloud provider, protected inside a \gls{tee}. 
We consider clients to be benchmark applications only, responsible of evaluating certain defined metrics for our experimental analysis shown later on this dissertation.

To make that interaction, a client first interacts with a proxy, which works as an intermediator. It acts as a single point of access and is responsible of authenticating everyone that wants to interact with the system. It is also in charge of the attestation process of the instances running inside the server, to check if they are trustable and going to execute as they are expected to. 

TODO - 

1)talk more about attestation

2)create a nice image of the overview:

Client -> Cloud [ 	  (Proxy)		]
				    (Attestation)
				   (Authentication)
					     |
					     v
				[	(KVS in-memory)	]
				
(ver figura do hj no desktop)

example of image from preparation
\begin{figure}[htbp]
	\centering
	{\includegraphics[width=0.4\linewidth]{SystemModelFinal}}
	\caption{Overview of the System Model}
	\label{fig:systemModel}
\end{figure}

\section{Threat model and security properties} % (fold)
\label{sec:threatModel_and_securityProperties}

Our solution is designed to offer privacy-enhanced guarantees in protecting data confidentiality, while also ensuring integrity and completeness of results returned to the clients, and we do it by ensuring that the sensitive data never runs in plaintext. By doing so, our system model protects from attackers with intentions of accessing sensitive data and taking advantage and value from it, regardless if the attack is coming from the inside or the outside the cloud system.


\subsection{Adversarial model definition}

We focused on two types of malefic users: 1- Users that attack the system and find a way of getting access to high privileges, such as capacity to manipulate the host \gls{os} and other low level components, through which he can get access to data running, and 2-  Honest-but-curious users, which already have higher privileges and can snoop on private data so they can learn and take advantage of it.

TODO - what is out of scope
1- client
2- proxy
3- storage
write something like: it is important to refer that with this prototype we dont offer storage confidentiality, because we only considered in-memory KVSs, although this is easily added to the system because redis can be configurated to work with persistent memory bla bla bla

\subsection{Countermeasures for privacy-preservation}

Since our objectives are pointed towards an isolated system capable of offering security
and privacy properties, we depend a lot on isolation techniques to make this possible,
provided by both hardware and software (containers).

As for hardware isolation, we looked at \gls{tee} technologies capable of assuring computation and storage security to our system's data during runtime.

Also, to grant an extra layer of isolation and to ensure privacy to the data in each element of our model we opted to use containerization, as a way to keep them independent and the system modular and scalable, enabling ease in the deployment of software running inside the containers, whether it is an OS, a library
OS or even entire applications. Running our system inside containers allows it to be deployed, in a very similar way, whether running locally or in the cloud, which came to be very handy in the implementation process. 

We didn't recurr to persisting data in storage to relieve some of the complexity that can arise due to the use of containers.



TODO - Put some figure of the containers for the proxy + authServer + attestationServer + KVS talking to each other or something that shows how modular/independent they are





\section{SGX Enabled REDIS solution} % (fold)
\label{sec:sgx_redis_solution}

Our solution, which is based on the system model introduced in Section \cite{sec:systemModel_overview}, can be divided in two pieces. One being the Client-side, responsable for making requests to the system, and other being the system itself, or the server. 

The system, which we run in a Cloud server, can be composed in two subdivisions: a Proxy server, and a \gls{kvs} server, all running inside containers on top of a \gls{tee}. 

As for the Client-side, we only considered them to be benchmark applications, and not entire web applications, with only the intent to evaluate the system.

TODO - say if the client are considered trusted or not


\subsection{System Architecture and Components}

The system itself runs on top of a \gls{tee}, that being Intel-\gls{sgx}. As we studied, applications can't simply be placed on top of a \gls{tee}, in this case \gls{sgx}, and expect them to perform the same way as they do without this extra layer of security. 
Hence, we opted to use SCONE \cite{ssec:scone} as a way to run our system. It allowed us to run the server components on containers capable of running with effectiveness on top of \gls{sgx}, with properties that ease the downsides of \gls{tee}s. 

For the KVS server, we used the Redis \gls{kvs} that can be used with different configurations, offering multiple strenghts to the execution and storage of data, especially if run in Cluster mode, offering scalability, fault-tolerance and even increase of performance if each replica of the cluster is set in independent machines.
 
In our solution we deployed Redis instances configurated in Standalone mode, Master-Slave mode and Cluster mode, as a way to test the behavior of the system. It's also important to note that each Redis replica had their own container, regardless which configuration it was set to execute. The test consisting on running each replica in independent machines was not possible, due to lack of resources.   

As for the proxy, it was implemented to have multiple purposes. First of all, it is used as a gateway for the system to communicate with the outside components.  It acts as a single point of access, enabling the rest of the system to scale, adding no extra complexity to the client-side. Thus, all the client has to do is to reach the proxy endpoint, while the redirection logic to the server instance that will manage the request will be done by the proxy itself. It is also the responsible of authenticating anyone from outside that want to interact with the system. Finally, we implemented the proxy to be in charge of attestating the components running in the rest of the server. 

All the communications between the components that compose the server-side are secured by TLS over HTTP, as a way to keep confidentiality of the data during communications all over the system.

\subsection{Client-Side Operations}

For the client-side, as mentioned in the beginning of this section, we only considered benchmarks. We use these benchmark clients with the single purpose of evaluating the system by making simple requests to the API (the Proxy), and calculate metrics that we found interesting to use in our pratical evaluation of the solution. 

They communicate with the Server-side also through TLS over HTTP.

% section importing_images (end)
\section{Open Design Issues} % (fold)

\section{Summary} % (fold)

Looking at our system model introduced in \ref{fig:systemModel}, there are some potential threats that need to be taken care of. First, the connection between the client and the \gls{kvs} needs to be secured. Secondly, the data being stored at the storage layer needs to be encrypted, otherwise it can be accessed and read, or even stolen. Considering only one \gls{kvs} will induce into a single point of failure on the processing layer. Finally, the data stored and running inside this layer along with its memory need to be secured. 

This can be achieved by using \gls{tls} over the \gls{http} protocol, securing the communication between the client and the \gls{kvs} layer.  Existing \gls{fde} technology can be used to encrypt the data to be stored in the storage layer. Finally, for the processing layer, we will use a cluster of \gls{kvs}, thus adding redundancy and load balancing. As for the security and privacy concerns, by isolating each cluster replica inside individual \gls{tee}s, we achieve confidentiality and privacy of the data during runtime. Figure \ref{fig:systemModelCluster} shows an overall idea of this proposed solution.

\begin{figure}[htbp]
	\centering
	{\includegraphics[width=0.4\linewidth]{SystemModelWithCluster}}
	\caption{System Model with a Key-Value Store Cluster}
	\label{fig:systemModelCluster}
\end{figure}

As a way to scale the overall system to modern requirements, we opted to divide it into two parts, one being the client layer and the other being both the processing and storage layers, which will both be implemented inside a cloud system. With this approach (figure \ref{fig:systemModelCloud}) we will guarantee scalability of the resources for the solution. 

\begin{figure}[htbp]
	\centering
	{\includegraphics[width=0.4\linewidth]{SystemModelCloud}}
	\caption{System Model running inside a Cloud System}
	\label{fig:systemModelCloud}
\end{figure}

The primary vision and goal of the generic architecture, as explained, is the support for a replicated storage service encompassing independent REDIS \gls{kvs} base instances running in independent SGX-enabled servers, running as replicated containers. However, other specialized containers (such as containers implementing a trusted OAUth authentication service, a trusted reference monitor implementing access-control enforcement and a trusted \gls{raid}-drive component to access \gls{raid} disks) can be considered as candidates to be composed in a final distributed architecture, possibly orchestrated in a Cloud Kubernetes deployment and management environment.

\section{Implementation Guidelines} % (fold)

For the development phase of this dissertation, and as we mentioned before in \ref{sec:objectiveAndContibutions}, we considered the following guidelines:

\textbf{Key-Value Store}: we opted for REDIS (v5.0.7) due to being the most popular \gls{kvs} at the moment, as we can see in \cite{rankingKVStores}. Adding this to the fact that it fits our system needs, we thought that an exhaustive study over this technology running in a dependable system would be an interesting contribution.

\textbf{Trusted Execution Environment}: as mentioned before, we choose to go with Intel-\gls{sgx} (\ref{ssec:intelsgx}), since it offers the possibility to isolate code inside multiple enclaves while executing on commodity hardware. Thus, we can run each node of our \gls{kvs} cluster inside of an individual enclave, assuring confidentiality and privacy of the data during runtime.

\textbf{OS library}: to run unmodified applications on top of Intel-\gls{sgx}, we picked Graphene-SGX (\ref{ssec:grapheneSGX}) as it was proven to be able to keep decent levels of performance in a system.

\textbf{Containerized OS Virtualization}: we choose Graphene-SGX Secure Container (GSC) \cite{gsc} due to being an open-source container system where an application can be protected by Intel-\gls{sgx} while running inside a Docker \cite{docker} container. We thought it to be a good way of adding an extra layer of isolation to the execution of each \gls{kvs} instance, while still running with the benefits of Graphene-SGX and Intel-\gls{sgx}.

\textbf{Cloud Infrastructure}: OVH \cite{ovhCloud} was the cloud provider chosen, mainly due to the fact that it supports \gls{sgx} in its dedicated servers.

\textbf{Operating System}: as for the \gls{os}, we are going to work with Ubuntu Linux, with the support of Linux-SGX \cite{linuxSGXwebsite} to run it on top of Intel-SGX technology. The use of Intel-SGX SDK \cite{linuxSgxSDK} for Linux makes it possible for us to manipulate the enclaves. Finally, we will use Linux SGX Driver \cite{linuxSGXDrivers}, which will manage the drivers of Linux-SGX already mentioned.

As for other technologies, the system will be written in Java. 
The client layer will consist of a benchmark application provided by both REDIS Benchmark and Yahoo! Cloud Serving Benchmark (YCSB) \cite{ycsb}. 
Jedis (REDIS java client) \cite{jedis} will also be used in the processing layer, as the client to our \gls{kvs} instances, along with Lettuce \cite{lettuce} for thread-safe operations when working with a \gls{kvs} cluster.


\section{Validation and Experimental Analysis} % (fold)
\label{sec:floats_figures_and_captions}

To validate and evaluate our solution, we created a set of tests for each metric we choose to evaluate. The analysis will be done between two scenarios, one being a regular, already existing, version of REDIS \gls{kvs}, while the other being a version of our TREDIS solution.

For this purpose we will be comparing the following metrics:

\begin{itemize}
	\item \textbf{Attestation latency:} time of the attestation between the client and REDIS;
	\item \textbf{Performance:} throughput and latency over the REDIS \gls{kvs};
	\item \textbf{Scalability:} scalability conditions under different client-workloads;
	\item \textbf{Resource allocation:} use of resources during runtime, including memory, CPU usage, I/O and energy.
\end{itemize}

In order to evaluate these metrics, we will analyze scenarios where:

\textbf{1)} the size of the datasets used in the benchmark tools scale up (e.g: 1,000 entries and 100,000 entries);

\textbf{2)} the typology of operations made over the \gls{kvs} varies: ratio of read/write operations (e.g: 20R/80W, 50R/50W, 80R/20W).


For the TREDIS solution running in an OVH cloud, our experimental evaluation will be conducted in development and deployment nodes with the following aspect:

\textbf{Processor:} Intel 2x Xeon Silver 4214 - 24 c / 48 t - 2.2 GHz / 3.2 GHz

\textbf{Memory:} 192 GB

\textbf{Storage:} NVMe, SATA dispon√≠vel

\textbf{Public Network:} more than 1Gb/s

\textbf{Private Network:} more than 2Gb/s

\textbf{OS:} CentOS 7.4.1708 64 bits or Ubuntu 18.4 LTS Server 64 bits



% \subsection{Inserting Figures Wrapped with text} % (fold)
% \label{ssec:inserting_images_wrapped_with_text}
% 
% You should only use this feature is \emph{really} necessary. This means, you have a very small image, that will look lonely just with text above and below.
% 
% In this case, you must use the \verb!wrapfiure! package.  To use \verb!wrapfig!, you must first add this to the preamble:
% 
% \begin{wrapfigure}{l}{2.5cm}
%   \centering
%     \includegraphics[width=2cm]{snowman-vectorial}
%   \caption{A snow-man}
% \end{wrapfigure}	
% 
% \noindent\verb!\usepackage{wrapfig}!\\
% This then gives you access to:\\
% \verb!\begin{wrapfigure}[lineheight]{alignment}{width}!\\
% Alignment can normally be either ``l'' for left, or ``r'' for right. Lowercase ``l'' or ``r'' forces the figure to start precisely where specified (and may cause it to run over page breaks), while capital ``L'' or ``R'' allows the figure to float. If you defined your document as twosided, the alignment can also be ``i'' for inside or ``o'' for outside, as well as ``I'' or ``O''. The width is obviously the width of the figure. The example above was introduced with:
% \lstset{language=TeX, morekeywords={\begin,\includegraphics,\caption}, caption=Wrapfig Example, label=lst:latex_example}
% \begin{lstlisting}
% 	\begin{wrapfigure}{l}{2.5cm}
% 	  \centering
% 	    \includegraphics[width=2cm]{snowman-vectorial}
% 	  \caption{A snow-man}
% 	\end{wrapfigure}	
% \end{lstlisting}

% subsection inserting_images_wrapped_with_text (end)

% section floats_figures_and_captions (end)

